{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using video_folder: /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed\n",
      "Processing directory: 10\n",
      "Found 101 normal CSV files in /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed/10/normal\n",
      "Found 58 abnormal CSV files in /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed/10/abnormal\n",
      "Processing directory: 11\n",
      "Found 248 normal CSV files in /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed/11/normal\n",
      "Found 103 abnormal CSV files in /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed/11/abnormal\n",
      "Processing directory: 12\n",
      "Found 206 normal CSV files in /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed/12/normal\n",
      "Found 70 abnormal CSV files in /home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed/12/abnormal\n",
      "Loaded 786 trajectories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115528/3473728532.py:72: RuntimeWarning: divide by zero encountered in divide\n",
      "  return distances / dt\n",
      "/home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:191: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "/tmp/ipykernel_115528/3473728532.py:72: RuntimeWarning: invalid value encountered in divide\n",
      "  return distances / dt\n",
      "/home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:1496: RuntimeWarning: invalid value encountered in subtract\n",
      "  a = op(a[slice1], a[slice2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. Sample data:\n",
      "   track_id  label  speed_variance  max_acceleration  direction_variance  \\\n",
      "0         1      0        0.265442          0.914214            6.992715   \n",
      "1         2      0       11.990207         13.500064           16.192243   \n",
      "2         3      0        2.742187          7.433034            0.217069   \n",
      "3         4      0        7.259035          8.997568           13.449146   \n",
      "4         5      0       17.242700         42.074009           15.200677   \n",
      "\n",
      "   circular_adherence  path_efficiency  number_of_sharp_turns  \\\n",
      "0            0.818975         0.245147                      4   \n",
      "1            0.216107         0.988577                     15   \n",
      "2            0.704500         0.991076                      4   \n",
      "3            0.581755         0.993253                     87   \n",
      "4            0.471818         0.983496                    109   \n",
      "\n",
      "   zone_transition_count  forbidden_transitions  \n",
      "0                      0                      0  \n",
      "1                      0                      0  \n",
      "2                      1                      1  \n",
      "3                      2                      2  \n",
      "4                      2                      2  \n",
      "Prepared 786 samples with 8 features.\n",
      "\n",
      "Hybrid Classification Results (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       119\n",
      "           1       0.50      0.54      0.52        39\n",
      "\n",
      "    accuracy                           0.75       158\n",
      "   macro avg       0.67      0.68      0.68       158\n",
      "weighted avg       0.76      0.75      0.76       158\n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "Feature Importances:\n",
      "                 Feature  Importance\n",
      "4        path_efficiency    0.238839\n",
      "3     circular_adherence    0.188221\n",
      "2     direction_variance    0.142800\n",
      "5  number_of_sharp_turns    0.109767\n",
      "0         speed_variance    0.106549\n",
      "1       max_acceleration    0.095076\n",
      "7  forbidden_transitions    0.060060\n",
      "6  zone_transition_count    0.058687\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for data processing, clustering, and classification\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Updated Data Loading Function ---\n",
    "def load_trajectories(video_folder: str) -> Tuple[List[pd.DataFrame], List[int]]:\n",
    "    \"\"\"\n",
    "    Load trajectory data from CSV files in 'normal' and 'abnormal' subfolders within each numbered directory.\n",
    "\n",
    "    Args:\n",
    "        video_folder (str): Path to the parent folder containing numbered directories (e.g., '10', '11', '12').\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[pd.DataFrame], List[int]]: List of trajectory DataFrames and their labels (0: normal, 1: abnormal).\n",
    "    \"\"\"\n",
    "    trajectories, labels = [], []\n",
    "\n",
    "    # Walk through the video_folder to find all numbered directories\n",
    "    for root, dirs, files in os.walk(video_folder):\n",
    "        # Check if the current directory has 'normal' and 'abnormal' subfolders\n",
    "        if 'normal' in dirs and 'abnormal' in dirs:\n",
    "            numbered_dir = os.path.basename(root)\n",
    "            print(f\"Processing directory: {numbered_dir}\")\n",
    "\n",
    "            # Load from 'normal' folder\n",
    "            normal_path = os.path.join(root, 'normal')\n",
    "            normal_files = [os.path.join(normal_path, f) for f in os.listdir(normal_path) if f.endswith('.csv')]\n",
    "            print(f\"Found {len(normal_files)} normal CSV files in {normal_path}\")\n",
    "            for file in normal_files:\n",
    "                df = pd.read_csv(file)[['frameNo', 'left', 'top', 'w', 'h']].sort_values(by='frameNo')\n",
    "                trajectories.append(df)\n",
    "                labels.append(0)  # Label 0 for normal\n",
    "\n",
    "            # Load from 'abnormal' folder\n",
    "            abnormal_path = os.path.join(root, 'abnormal')\n",
    "            abnormal_files = [os.path.join(abnormal_path, f) for f in os.listdir(abnormal_path) if f.endswith('.csv')]\n",
    "            print(f\"Found {len(abnormal_files)} abnormal CSV files in {abnormal_path}\")\n",
    "            for file in abnormal_files:\n",
    "                df = pd.read_csv(file)[['frameNo', 'left', 'top', 'w', 'h']].sort_values(by='frameNo')\n",
    "                trajectories.append(df)\n",
    "                labels.append(1)  # Label 1 for abnormal\n",
    "\n",
    "    return trajectories, labels\n",
    "\n",
    "# --- Helper Functions for Feature Extraction ---\n",
    "def df_to_points(df: pd.DataFrame) -> List[Tuple[int, float, float]]:\n",
    "    \"\"\"Convert DataFrame to a list of (frame_id, x, y) points, using center of bounding box.\"\"\"\n",
    "    points = []\n",
    "    for _, row in df.iterrows():\n",
    "        frame_id = int(row['frameNo'])\n",
    "        x = row['left'] + row['w'] / 2\n",
    "        y = row['top'] + row['h'] / 2\n",
    "        points.append((frame_id, x, y))\n",
    "    return points\n",
    "\n",
    "def calculate_speed(points: List[Tuple[int, float, float]], fps: float) -> np.ndarray:\n",
    "    \"\"\"Calculate speed between consecutive points.\"\"\"\n",
    "    dx = np.diff([p[1] for p in points])\n",
    "    dy = np.diff([p[2] for p in points])\n",
    "    dt = np.diff([p[0] for p in points]) / fps\n",
    "    distances = np.sqrt(dx**2 + dy**2)\n",
    "    return distances / dt\n",
    "\n",
    "def calculate_acceleration(points: List[Tuple[int, float, float]], fps: float) -> np.ndarray:\n",
    "    \"\"\"Calculate acceleration based on speed changes.\"\"\"\n",
    "    speeds = calculate_speed(points, fps)\n",
    "    dt = np.diff([p[0] for p in points][:-1]) / fps  # Adjust for speed array length\n",
    "    return np.diff(speeds) / dt\n",
    "\n",
    "def calculate_direction_variance(points: List[Tuple[int, float, float]]) -> float:\n",
    "    \"\"\"Calculate variance in direction (angle) between consecutive points.\"\"\"\n",
    "    dx = np.diff([p[1] for p in points])\n",
    "    dy = np.diff([p[2] for p in points])\n",
    "    angles = np.arctan2(dy, dx)\n",
    "    return np.var(np.diff(angles)) if len(angles) > 1 else 0.0\n",
    "\n",
    "def derive_roundabout_geometry(normal_trajectories: List[pd.DataFrame]) -> Tuple[float, float, float]:\n",
    "    \"\"\"Derive roundabout center and radius from normal trajectories using KMeans.\"\"\"\n",
    "    all_points = []\n",
    "    for traj_df in normal_trajectories:\n",
    "        points = df_to_points(traj_df)\n",
    "        all_points.extend([(p[1], p[2]) for p in points])\n",
    "    if not all_points:\n",
    "        return 0.0, 0.0, 100.0  # Default values\n",
    "    points_array = np.array(all_points)\n",
    "    kmeans = KMeans(n_clusters=1).fit(points_array)\n",
    "    center_x, center_y = kmeans.cluster_centers_[0]\n",
    "    distances = np.sqrt((points_array[:, 0] - center_x)**2 + (points_array[:, 1] - center_y)**2)\n",
    "    radius = np.median(distances)\n",
    "    return center_x, center_y, radius\n",
    "\n",
    "def calculate_circular_adherence(points: List[Tuple[int, float, float]], center_x: float, center_y: float, radius: float) -> float:\n",
    "    \"\"\"Measure how closely the trajectory adheres to a circular path.\"\"\"\n",
    "    distances = np.sqrt((np.array([p[1] for p in points]) - center_x)**2 + (np.array([p[2] for p in points]) - center_y)**2)\n",
    "    return 1.0 - np.mean(np.abs(distances - radius)) / radius if len(distances) > 0 else 0.0\n",
    "\n",
    "def calculate_path_efficiency(points: List[Tuple[int, float, float]]) -> float:\n",
    "    \"\"\"Calculate efficiency as straight-line distance divided by total path length.\"\"\"\n",
    "    total_distance = np.sum(np.sqrt(np.diff([p[1] for p in points])**2 + np.diff([p[2] for p in points])**2))\n",
    "    start_end_distance = np.sqrt((points[-1][1] - points[0][1])**2 + (points[-1][2] - points[0][2])**2)\n",
    "    return start_end_distance / total_distance if total_distance > 0 else 1.0\n",
    "\n",
    "def calculate_number_of_sharp_turns(points: List[Tuple[int, float, float]], threshold: float = np.pi/4) -> int:\n",
    "    \"\"\"Count sharp turns based on angle changes exceeding a threshold.\"\"\"\n",
    "    dx = np.diff([p[1] for p in points])\n",
    "    dy = np.diff([p[2] for p in points])\n",
    "    angles = np.arctan2(dy, dx)\n",
    "    angle_changes = np.abs(np.diff(angles))\n",
    "    return np.sum(angle_changes > threshold) if len(angle_changes) > 0 else 0\n",
    "\n",
    "def calculate_zone_transition_count(points: List[Tuple[int, float, float]], center_x: float, center_y: float, radius: float) -> int:\n",
    "    \"\"\"Count transitions across a simplified zone boundary (inside/outside circle).\"\"\"\n",
    "    distances = np.sqrt((np.array([p[1] for p in points]) - center_x)**2 + (np.array([p[2] for p in points]) - center_y)**2)\n",
    "    inside = distances < radius\n",
    "    return np.sum(np.diff(inside.astype(int)) != 0) if len(inside) > 1 else 0\n",
    "\n",
    "def calculate_forbidden_transitions(points: List[Tuple[int, float, float]], center_x: float, center_y: float, radius: float) -> int:\n",
    "    \"\"\"Count forbidden transitions (simplified as erratic jumps across zones).\"\"\"\n",
    "    distances = np.sqrt((np.array([p[1] for p in points]) - center_x)**2 + (np.array([p[2] for p in points]) - center_y)**2)\n",
    "    zones = (distances < radius).astype(int)  # 0: outside, 1: inside\n",
    "    transitions = np.diff(zones)\n",
    "    return np.sum(transitions != 0) if len(transitions) > 0 else 0\n",
    "\n",
    "# --- Feature Extraction ---\n",
    "def extract_features(trajectories: List[pd.DataFrame], labels: List[int], fps: float) -> pd.DataFrame:\n",
    "    \"\"\"Extract features from a list of trajectories.\"\"\"\n",
    "    normal_trajectories = [traj for traj, label in zip(trajectories, labels) if label == 0]\n",
    "    center_x, center_y, radius = derive_roundabout_geometry(normal_trajectories)\n",
    "\n",
    "    results = []\n",
    "    for idx, (traj_df, label) in enumerate(zip(trajectories, labels)):\n",
    "        points = df_to_points(traj_df)\n",
    "        speeds = calculate_speed(points, fps)\n",
    "        accels = calculate_acceleration(points, fps)\n",
    "\n",
    "        features = {\n",
    "            'track_id': idx + 1,\n",
    "            'label': label,\n",
    "            'speed_variance': np.var(speeds) if len(speeds) > 0 else 0.0,\n",
    "            'max_acceleration': np.max(np.abs(accels)) if len(accels) > 0 else 0.0,\n",
    "            'direction_variance': calculate_direction_variance(points),\n",
    "            'circular_adherence': calculate_circular_adherence(points, center_x, center_y, radius),\n",
    "            'path_efficiency': calculate_path_efficiency(points),\n",
    "            'number_of_sharp_turns': calculate_number_of_sharp_turns(points),\n",
    "            'zone_transition_count': calculate_zone_transition_count(points, center_x, center_y, radius),\n",
    "            'forbidden_transitions': calculate_forbidden_transitions(points, center_x, center_y, radius)\n",
    "        }\n",
    "        results.append(features)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Data Preprocessing and Cleaning ---\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean the DataFrame by replacing NaN/infinite values with 0.\"\"\"\n",
    "    return df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the path to the parent folder containing numbered directories\n",
    "    video_folder = \"/home/run/media/localdiskD/Ahmedabad University/6th SEM/ML/ML_2025_4_Cluster_555/dataset(Copy)/processed\"\n",
    "    print(f\"Using video_folder: {video_folder}\")\n",
    "\n",
    "    # Load trajectories from all numbered directories\n",
    "    trajectories, labels = load_trajectories(video_folder)\n",
    "    print(f\"Loaded {len(trajectories)} trajectories.\")\n",
    "\n",
    "    if len(trajectories) == 0:\n",
    "        print(\"No trajectories loaded. Check the directory structure and file paths.\")\n",
    "    else:\n",
    "        # Extract features\n",
    "        fps = 1.0  # Adjust based on your video's frame rate\n",
    "        features_df = extract_features(trajectories, labels, fps)\n",
    "        print(\"Feature extraction complete. Sample data:\")\n",
    "        print(features_df.head())\n",
    "\n",
    "        # Clean data\n",
    "        cleaned_df = clean_dataframe(features_df)\n",
    "\n",
    "        # Prepare feature matrix and labels\n",
    "        numeric_features = [\n",
    "            'speed_variance', 'max_acceleration', 'direction_variance', 'circular_adherence',\n",
    "            'path_efficiency', 'number_of_sharp_turns', 'zone_transition_count', 'forbidden_transitions'\n",
    "        ]\n",
    "        X = cleaned_df[numeric_features]\n",
    "        y = cleaned_df['label']\n",
    "        print(f\"Prepared {len(X)} samples with {len(numeric_features)} features.\")\n",
    "\n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Step 1: Apply DBSCAN for initial anomaly detection\n",
    "        db = DBSCAN(eps=0.5, min_samples=5).fit(X_scaled)\n",
    "        cluster_labels = db.labels_\n",
    "        initial_preds = [1 if label == -1 else 0 for label in cluster_labels]  # -1: outlier (abnormal)\n",
    "\n",
    "        # Step 2: Train Random Forest on labeled data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        clf = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Evaluate results\n",
    "        print(\"\\nHybrid Classification Results (Random Forest):\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "        # Display feature importances\n",
    "        print(\"\\nFeature Importances:\")\n",
    "        importances = pd.DataFrame({'Feature': numeric_features, 'Importance': clf.feature_importances_})\n",
    "        print(importances.sort_values(by='Importance', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
