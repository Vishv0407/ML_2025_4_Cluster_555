{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ljBeSWJaJm",
        "outputId": "f0ca47a0-acc1-4df7-d27a-f94594653d53"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/bin/python -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!unzip /content/sample_data/processed.zip -d /content/sample_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3xUjUGaQq-Q",
        "outputId": "3a163968-54dc-45b3-9fa3-58ab5157aabb"
      },
      "outputs": [],
      "source": [
        "# Install required packages (if not already installed in Colab)\n",
        "!pip install numpy pandas scikit-learn matplotlib\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "import argparse\n",
        "from google.colab import files  # For file upload in Colab\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from scipy.stats import pointbiserialr\n",
        "\n",
        "print(\"Dependencies and imports set up.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yrTbp-U84ne1",
        "outputId": "67a686a2-6ab4-40d3-e71a-8b3269a37846"
      },
      "outputs": [],
      "source": [
        "# Set the base directory containing the abnormal and normal subfolders\n",
        "base_directory = '/content/sample_data/processed/10'\n",
        "\n",
        "# Define subdirectories for abnormal and normal tracks\n",
        "abnormal_dir = os.path.join(base_directory, 'abnormal')\n",
        "normal_dir = os.path.join(base_directory, 'normal')\n",
        "\n",
        "# Step 1: Load CSV files from both directories\n",
        "def load_trajectories(abnormal_dir, normal_dir):\n",
        "    tracks = {}\n",
        "\n",
        "    # Load abnormal tracks\n",
        "    if os.path.exists(abnormal_dir):\n",
        "        abnormal_files = [f for f in os.listdir(abnormal_dir) if f.endswith('.csv')]\n",
        "        for csv_file in abnormal_files:\n",
        "            file_path = os.path.join(abnormal_dir, csv_file)\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)[['frameNo', 'left', 'top', 'w', 'h']]\n",
        "                if not df.empty:\n",
        "                    # Extract track ID (first number before '_', or full filename if no '_')\n",
        "                    track_id = csv_file.split('_')[0] if '_' in csv_file else csv_file.replace('.csv', '')\n",
        "                    tracks[track_id] = {'df': df, 'label': 0}  # 0 for abnormal\n",
        "                    print(f\"Loaded {csv_file} from abnormal folder with {len(df)} rows for track ID {track_id}.\")\n",
        "                else:\n",
        "                    print(f\"Warning: {csv_file} is empty and will be skipped.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {csv_file} from abnormal folder: {e}\")\n",
        "    else:\n",
        "        print(f\"Warning: Abnormal directory {abnormal_dir} not found.\")\n",
        "\n",
        "    # Load normal tracks\n",
        "    if os.path.exists(normal_dir):\n",
        "        normal_files = [f for f in os.listdir(normal_dir) if f.endswith('.csv')]\n",
        "        for csv_file in normal_files:\n",
        "            file_path = os.path.join(normal_dir, csv_file)\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)[['frameNo', 'left', 'top', 'w', 'h']]\n",
        "                if not df.empty:\n",
        "                    # Extract track ID (first number before '_', or full filename if no '_')\n",
        "                    track_id = csv_file.split('_')[0] if '_' in csv_file else csv_file.replace('.csv', '')\n",
        "                    tracks[track_id] = {'df': df, 'label': 1}  # 1 for normal\n",
        "                    print(f\"Loaded {csv_file} from normal folder with {len(df)} rows for track ID {track_id}.\")\n",
        "                else:\n",
        "                    print(f\"Warning: {csv_file} is empty and will be skipped.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {csv_file} from normal folder: {e}\")\n",
        "    else:\n",
        "        print(f\"Warning: Normal directory {normal_dir} not found.\")\n",
        "\n",
        "    return tracks\n",
        "\n",
        "# Step 2: Compute centers\n",
        "def compute_centers(tracks):\n",
        "    for track_id, data in tracks.items():\n",
        "        df = data['df']\n",
        "        df['center_x'] = df['left'] + df['w'] / 2\n",
        "        df['center_y'] = df['top'] + df['h'] / 2\n",
        "\n",
        "# Step 3: Plot all trajectories in one image\n",
        "def plot_all_trajectories(tracks):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    colors = {'0': 'red', '1': 'green'}  # Red for abnormal, Green for normal\n",
        "\n",
        "    for track_id, data in tracks.items():\n",
        "        df = data['df']\n",
        "        label = str(data['label'])\n",
        "        color = colors[label]\n",
        "\n",
        "        # Plot the trajectory without labels\n",
        "        plt.scatter(df['center_x'], df['center_y'], c=color, alpha=0.5)\n",
        "        plt.plot(df['center_x'], df['center_y'], c=color, alpha=0.3)\n",
        "\n",
        "    # Remove labels, title, and legend\n",
        "    plt.title('')  # Empty title\n",
        "    plt.xlabel('')  # Empty x-axis label\n",
        "    plt.ylabel('')  # Empty y-axis label\n",
        "    plt.grid(False)  # No grid\n",
        "    plt.xticks([])  # Remove x-axis ticks\n",
        "    plt.yticks([])  # Remove y-axis ticks\n",
        "\n",
        "    # Save the plot as an image\n",
        "    output_path = os.path.join(base_directory, 'all_trajectories.png')\n",
        "    plt.savefig(output_path, bbox_inches='tight')\n",
        "    print(f\"Saved plot to {output_path}\")\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load trajectories from both folders\n",
        "    tracks = load_trajectories(abnormal_dir, normal_dir)\n",
        "    if not tracks:\n",
        "        print(\"No valid trajectories loaded. Exiting.\")\n",
        "        exit()\n",
        "\n",
        "    # Compute centers\n",
        "    compute_centers(tracks)\n",
        "\n",
        "    # Plot all trajectories in one image\n",
        "    plot_all_trajectories(tracks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xkQno5HQuRD",
        "outputId": "0a3da583-9a22-472d-d1c4-9ae02bfdb909"
      },
      "outputs": [],
      "source": [
        "# Define a data class for a vehicle's track point\n",
        "@dataclass\n",
        "class TrackPoint:\n",
        "    frame_id: int  # Frame number from CSV (continuous)\n",
        "    x: float       # 'left' coordinate of bounding box\n",
        "    y: float       # 'top' coordinate of bounding box\n",
        "    zone_id: int   # Assigned zone ID\n",
        "\n",
        "VehicleTrack = List[TrackPoint]\n",
        "\n",
        "# Define the TrafficAnalyzer class for feature extraction\n",
        "class TrafficAnalyzer:\n",
        "    def __init__(self, fps: float, speed_limit: float, zone_definitions: Dict,\n",
        "                 violation_dict: Dict[str, List[str]], gsd: float):\n",
        "        \"\"\"Initialize with project-specific parameters.\"\"\"\n",
        "        self.fps = fps\n",
        "        self.speed_limit = speed_limit\n",
        "        self.zone_definitions = zone_definitions\n",
        "        self.violation_dict = violation_dict\n",
        "        self.gsd = gsd\n",
        "\n",
        "    def calculate_speed(self, track: VehicleTrack) -> List[float]:\n",
        "        \"\"\"Calculate speed using frame differences as time intervals.\"\"\"\n",
        "        speeds = []\n",
        "        for i in range(1, len(track)):\n",
        "            dx = (track[i].x - track[i-1].x) * self.gsd\n",
        "            dy = (track[i].y - track[i-1].y) * self.gsd\n",
        "            distance = math.sqrt(dx**2 + dy**2)\n",
        "            time = (track[i].frame_id - track[i-1].frame_id) / self.fps\n",
        "            speed_mps = distance / time if time > 0 else 0\n",
        "            speed_kmph = speed_mps * 3.6\n",
        "            speeds.append(speed_kmph)\n",
        "        return speeds\n",
        "\n",
        "    def calculate_turn_angle(self, track: VehicleTrack) -> List[float]:\n",
        "        \"\"\"Calculate turn angles using three consecutive points.\"\"\"\n",
        "        angles = []\n",
        "        for i in range(2, len(track)):\n",
        "            v1 = (track[i-1].x - track[i-2].x, track[i-1].y - track[i-2].y)\n",
        "            v2 = (track[i].x - track[i-1].x, track[i].y - track[i-1].y)\n",
        "            dot_product = v1[0] * v2[0] + v1[1] * v2[1]\n",
        "            mag_v1 = math.sqrt(v1[0]**2 + v1[1]**2)\n",
        "            mag_v2 = math.sqrt(v2[0]**2 + v2[1]**2)\n",
        "            if mag_v1 * mag_v2 == 0:\n",
        "                angles.append(0)\n",
        "                continue\n",
        "            cos_theta = dot_product / (mag_v1 * mag_v2)\n",
        "            cos_theta = min(1.0, max(-1.0, cos_theta))\n",
        "            angle = math.degrees(math.acos(cos_theta))\n",
        "            angles.append(angle)\n",
        "        return angles\n",
        "\n",
        "    def get_zone_sequence(self, track: VehicleTrack) -> List[int]:\n",
        "        \"\"\"Get sequence of zones traversed.\"\"\"\n",
        "        return [point.zone_id for point in track]\n",
        "\n",
        "    def detect_abnormalities(self, track: VehicleTrack) -> Dict[str, bool]:\n",
        "        \"\"\"Detect abnormalities based on spatio-temporal features.\"\"\"\n",
        "        abnormalities = {\n",
        "            'over_speeding': False,\n",
        "            'wrong_side': False,\n",
        "            'wrong_turn': False,\n",
        "            'sharp_turn': False\n",
        "        }\n",
        "        speeds = self.calculate_speed(track)\n",
        "        if speeds and max(speeds) > self.speed_limit:\n",
        "            abnormalities['over_speeding'] = True\n",
        "\n",
        "        zone_seq = self.get_zone_sequence(track)\n",
        "        seq_str = ''.join(map(str, zone_seq))\n",
        "        for wrong_side_seq in self.violation_dict.get('wrong_side', []):\n",
        "            if wrong_side_seq in seq_str:\n",
        "                abnormalities['wrong_side'] = True\n",
        "                break\n",
        "        for wrong_turn_seq in self.violation_dict.get('wrong_turn', []):\n",
        "            if wrong_turn_seq in seq_str:\n",
        "                abnormalities['wrong_turn'] = True\n",
        "                break\n",
        "\n",
        "        angles = self.calculate_turn_angle(track)\n",
        "        if angles and max(angles) > 90:\n",
        "            abnormalities['sharp_turn'] = True\n",
        "\n",
        "        return abnormalities\n",
        "\n",
        "print(\"TrafficAnalyzer class defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUkClnl3QwdU",
        "outputId": "5caae2a8-28c3-4f3a-eea4-ebdce804ad83"
      },
      "outputs": [],
      "source": [
        "def assign_zone_id(x: float, y: float) -> int:\n",
        "    \"\"\"Assign zone based on coordinates (customize for your road layout).\"\"\"\n",
        "    if x < 250:\n",
        "        return 1  # Example: North zone\n",
        "    elif 250 <= x < 300:\n",
        "        return 2  # Example: Middle zone\n",
        "    else:\n",
        "        return 3  # Example: South zone\n",
        "\n",
        "def convert_df_to_track(df: pd.DataFrame) -> VehicleTrack:\n",
        "    \"\"\"Convert a DataFrame trajectory to a VehicleTrack.\"\"\"\n",
        "    track = []\n",
        "    for _, row in df.iterrows():\n",
        "        x = row['left']\n",
        "        y = row['top']\n",
        "        frame_id = int(row['frameNo'])\n",
        "        zone_id = assign_zone_id(x, y)\n",
        "        track.append(TrackPoint(frame_id=frame_id, x=x, y=y, zone_id=zone_id))\n",
        "    return track\n",
        "\n",
        "print(\"Helper functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usURtA9BQye9",
        "outputId": "c0efb21d-0de2-413d-9ebe-27589e5c764a"
      },
      "outputs": [],
      "source": [
        "def load_trajectories(video_folder: str) -> tuple[List[pd.DataFrame], List[int]]:\n",
        "    \"\"\"\n",
        "    Load trajectory data from CSV files in a video folder.\n",
        "\n",
        "    Parameters:\n",
        "    - video_folder (str): Path to the video folder (e.g., '/content/sample_data/processed/10')\n",
        "\n",
        "    Returns:\n",
        "    - trajectories (list): List of pandas DataFrames, each containing a trajectory\n",
        "    - labels (list): List of labels (0 for normal, 1 for abnormal)\n",
        "    \"\"\"\n",
        "    normal_path = os.path.join(video_folder, 'normal')\n",
        "    abnormal_path = os.path.join(video_folder, 'abnormal')\n",
        "\n",
        "    trajectories = []\n",
        "    labels = []\n",
        "\n",
        "    # Load normal trajectories\n",
        "    if os.path.exists(normal_path):\n",
        "        normal_files = [os.path.join(normal_path, f) for f in os.listdir(normal_path) if f.endswith('.csv')]\n",
        "        for file in normal_files:\n",
        "            df = pd.read_csv(file)\n",
        "            df = df[['frameNo', 'left', 'top', 'w', 'h']]\n",
        "            df = df.sort_values(by='frameNo')\n",
        "            trajectories.append(df)\n",
        "            labels.append(0)\n",
        "\n",
        "    # Load abnormal trajectories\n",
        "    if os.path.exists(abnormal_path):\n",
        "        abnormal_files = [os.path.join(abnormal_path, f) for f in os.listdir(abnormal_path) if f.endswith('.csv')]\n",
        "        for file in abnormal_files:\n",
        "            df = pd.read_csv(file)\n",
        "            df = df[['frameNo', 'left', 'top', 'w', 'h']]\n",
        "            df = df.sort_values(by='frameNo')\n",
        "            trajectories.append(df)\n",
        "            labels.append(1)\n",
        "\n",
        "    return trajectories, labels\n",
        "\n",
        "print(\"Trajectory loading function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHK08jQlQ1w0",
        "outputId": "966b7379-0d44-4637-fcb1-791535de3e47"
      },
      "outputs": [],
      "source": [
        "def extract_features_for_all_trajectories(trajectories: List[pd.DataFrame], labels: List[int],\n",
        "                                         analyzer: TrafficAnalyzer) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extract features and detect abnormalities for all trajectories.\n",
        "\n",
        "    Parameters:\n",
        "    - trajectories: List of DataFrames with trajectory data\n",
        "    - labels: List of labels (0=normal, 1=abnormal)\n",
        "    - analyzer: TrafficAnalyzer instance\n",
        "\n",
        "    Returns:\n",
        "    - results_df: DataFrame with features and abnormalities\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for idx, (traj_df, label) in enumerate(zip(trajectories, labels)):\n",
        "        track = convert_df_to_track(traj_df)\n",
        "        abnormalities = analyzer.detect_abnormalities(track)\n",
        "        speeds = analyzer.calculate_speed(track)\n",
        "        angles = analyzer.calculate_turn_angle(track)\n",
        "        zone_seq = analyzer.get_zone_sequence(track)\n",
        "\n",
        "        result = {\n",
        "            'track_id': idx + 1,\n",
        "            'label': label,\n",
        "            'over_speeding': abnormalities['over_speeding'],\n",
        "            'wrong_side': abnormalities['wrong_side'],\n",
        "            'wrong_turn': abnormalities['wrong_turn'],\n",
        "            'sharp_turn': abnormalities['sharp_turn'],\n",
        "            'max_speed': max(speeds) if speeds else 0.0,\n",
        "            'avg_speed': np.mean(speeds) if speeds else 0.0,\n",
        "            'max_turn_angle': max(angles) if angles else 0.0,\n",
        "            'avg_turn_angle': np.mean(angles) if angles else 0.0,\n",
        "            'zone_sequence': ','.join(map(str, zone_seq)),\n",
        "            'num_points': len(track)\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "print(\"Feature extraction function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2177
        },
        "id": "Zanl3FSRQ3wG",
        "outputId": "fce2b8ab-53f5-4297-ca60-d32f575c266a"
      },
      "outputs": [],
      "source": [
        "# Define base folder and video subfolders\n",
        "base_folder = '/content/sample_data/processed'  # Adjust this path\n",
        "video_folders = [\n",
        "    os.path.join(base_folder, '10'),\n",
        "    os.path.join(base_folder, '11'),\n",
        "    os.path.join(base_folder, '12')\n",
        "]\n",
        "\n",
        "# Load all trajectories\n",
        "all_trajectories = []\n",
        "all_labels = []\n",
        "for folder in video_folders:\n",
        "    if os.path.exists(folder):\n",
        "        traj, lbl = load_trajectories(folder)\n",
        "        all_trajectories.extend(traj)\n",
        "        all_labels.extend(lbl)\n",
        "    else:\n",
        "        print(f\"Warning: Folder {folder} does not exist.\")\n",
        "\n",
        "print(f\"Loaded {len(all_trajectories)} trajectories.\")\n",
        "\n",
        "# Initialize TrafficAnalyzer\n",
        "zone_definitions = {\n",
        "    1: {'type': 'entry', 'direction': 'N'},\n",
        "    2: {'type': 'middle', 'direction': 'center'},\n",
        "    3: {'type': 'exit', 'direction': 'S'}\n",
        "}\n",
        "violation_dict = {\n",
        "    'wrong_side': ['31'],\n",
        "    'wrong_turn': ['23']\n",
        "}\n",
        "analyzer = TrafficAnalyzer(\n",
        "    fps=30.0,\n",
        "    speed_limit=40.0,\n",
        "    zone_definitions=zone_definitions,\n",
        "    violation_dict=violation_dict,\n",
        "    gsd=0.0396 * (50 ** 0.9478)\n",
        ")\n",
        "\n",
        "# Extract features\n",
        "results_df = extract_features_for_all_trajectories(all_trajectories, all_labels, analyzer)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nSummary of Results:\")\n",
        "display(results_df[['track_id', 'label', 'over_speeding', 'wrong_side', 'wrong_turn', 'sharp_turn',\n",
        "                   'max_speed', 'max_turn_angle']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGfnY8LTSc-N",
        "outputId": "16a47d00-38ed-4e78-922f-b9d672499926"
      },
      "outputs": [],
      "source": [
        "# Save results to CSV\n",
        "results_df.to_csv('/content/sample_data/trajectory_features.csv', index=False)\n",
        "print(\"Features saved to '/content/sample_data/trajectory_features.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "E6s5OzQJXElK",
        "outputId": "2d6866d1-5b36-4985-cbe2-4d0db87835e4"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file\n",
        "features_df = pd.read_csv('/content/sample_data/trajectory_features.csv')  # Replace with your file path if different\n",
        "\n",
        "# Display the first few rows to inspect the data\n",
        "print(\"Original Data Sample:\")\n",
        "display(features_df.head())\n",
        "\n",
        "# Identify and drop noisy columns\n",
        "numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
        "constant_cols = [col for col in numeric_cols if features_df[col].nunique() <= 1 or features_df[col].sum() == 0]\n",
        "noisy_cols = ['max_speed', 'avg_speed', 'max_turn_angle', 'avg_turn_angle']  # Based on your data\n",
        "cols_to_drop = list(set(constant_cols + noisy_cols))\n",
        "\n",
        "# Drop noisy columns\n",
        "cleaned_df = features_df.drop(columns=cols_to_drop)\n",
        "\n",
        "# Convert boolean columns to integer (0 and 1) for analysis\n",
        "bool_cols = ['over_speeding', 'wrong_side', 'wrong_turn', 'sharp_turn']\n",
        "for col in bool_cols:\n",
        "    cleaned_df[col] = cleaned_df[col].astype(int)\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = cleaned_df.drop(columns=['track_id', 'label'])  # Features\n",
        "y = cleaned_df['label']  # Labels\n",
        "\n",
        "# Separate numeric and categorical features\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = ['zone_sequence']\n",
        "\n",
        "print(\"\\nCleaned Data Sample (after dropping noisy columns):\")\n",
        "display(cleaned_df.head())\n",
        "print(f\"Numeric Features: {numeric_features}\")\n",
        "print(f\"Categorical Features: {categorical_features}\")\n",
        "print(\"Data cleaned and prepared successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u6xpQWq1XeKH",
        "outputId": "813bd87a-f1a8-4ad0-c32a-d3a9cb76f15b"
      },
      "outputs": [],
      "source": [
        "# Calculate mean and standard deviation for numeric features only\n",
        "normal_group = cleaned_df[cleaned_df['label'] == 0]\n",
        "abnormal_group = cleaned_df[cleaned_df['label'] == 1]\n",
        "\n",
        "mean_normal = normal_group[numeric_features].mean()\n",
        "std_normal = normal_group[numeric_features].std()\n",
        "mean_abnormal = abnormal_group[numeric_features].mean()\n",
        "std_abnormal = abnormal_group[numeric_features].std()\n",
        "\n",
        "stats_df = pd.DataFrame({\n",
        "    'Mean_Normal': mean_normal,\n",
        "    'Std_Normal': std_normal,\n",
        "    'Mean_Abnormal': mean_abnormal,\n",
        "    'Std_Abnormal': std_abnormal\n",
        "})\n",
        "\n",
        "print(\"\\nStatistical Summary for Numeric Features by Class (Mean and Std Dev):\")\n",
        "display(stats_df)\n",
        "\n",
        "# Compute point-biserial correlation between each numeric feature and the label\n",
        "correlations = {}\n",
        "for col in numeric_features:\n",
        "    corr, _ = pointbiserialr(y, X[col])\n",
        "    correlations[col] = corr\n",
        "\n",
        "# Convert to DataFrame for display\n",
        "corr_df = pd.DataFrame(list(correlations.items()), columns=['Feature', 'Correlation'])\n",
        "corr_df = corr_df.sort_values(by='Correlation', key=abs, ascending=False)\n",
        "\n",
        "print(\"\\nPoint-Biserial Correlation with Label (Numeric Features):\")\n",
        "display(corr_df)\n",
        "\n",
        "# Visualize correlation values for numeric features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(corr_df['Feature'], corr_df['Correlation'], color='skyblue')\n",
        "plt.axhline(0, color='gray', linewidth=0.5)\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Correlation with Label (0=Normal, 1=Abnormal)')\n",
        "plt.title('Relevance of Numeric Features to Normal vs Abnormal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze zone_sequence (categorical) separately using frequency distribution\n",
        "zone_counts = cleaned_df.groupby(['label', 'zone_sequence']).size().unstack(fill_value=0)\n",
        "print(\"\\nZone Sequence Distribution by Label:\")\n",
        "display(zone_counts)\n",
        "\n",
        "# Calculate a chi-squared test to assess association between zone_sequence and label\n",
        "from scipy.stats import chi2_contingency\n",
        "chi2, p, _, _ = chi2_contingency(zone_counts)\n",
        "print(f\"\\nChi-Squared Test for zone_sequence vs Label:\")\n",
        "print(f\"Chi2 Statistic: {chi2:.2f}, p-value: {p:.4f}\")\n",
        "print(\"A low p-value (<0.05) indicates a significant association between zone_sequence and label.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEz3JeVSYfq3",
        "outputId": "3a1c6dfe-6e61-4ac3-e027-57a2f8cf5173"
      },
      "outputs": [],
      "source": [
        "# Summary of findings\n",
        "print(\"\\nRelevance Assessment:\")\n",
        "print(\"- Numeric features with |Correlation| > 0.3 are strong indicators for classification.\")\n",
        "print(\"- Significant differences in means between normal and abnormal classes suggest relevance.\")\n",
        "print(\"- For zone_sequence, a low p-value (<0.05) in the chi-squared test indicates relevance.\")\n",
        "\n",
        "# Highlight strongly relevant numeric features\n",
        "relevant_numeric_features = corr_df[abs(corr_df['Correlation']) > 0.3]['Feature'].tolist()\n",
        "if relevant_numeric_features:\n",
        "    print(f\"Strongly relevant numeric features: {relevant_numeric_features}\")\n",
        "else:\n",
        "    print(\"No numeric features with strong correlation (|corr| > 0.3).\")\n",
        "\n",
        "# Highlight zone_sequence relevance\n",
        "if p < 0.05:\n",
        "    print(\"zone_sequence appears relevant based on the chi-squared test (p < 0.05).\")\n",
        "else:\n",
        "    print(\"zone_sequence may not be strongly relevant (p >= 0.05). Consider encoding or deriving new features from it.\")\n",
        "\n",
        "# Recommendations\n",
        "print(\"\\nRecommendations:\")\n",
        "if relevant_numeric_features or p < 0.05:\n",
        "    print(\"- Some features appear relevant for distinguishing normal vs abnormal tracks.\")\n",
        "    print(\"- Proceed with these features for classification or further analysis.\")\n",
        "else:\n",
        "    print(\"- Features lack strong relevance. Consider the following:\")\n",
        "    print(\"  - Verify data quality: Ensure trajectories capture meaningful motion (speed, turns, etc.).\")\n",
        "    print(\"  - Feature engineering: Derive new features (e.g., zone transitions, sequence length).\")\n",
        "    print(\"  - Expand dataset: Include more diverse trajectories to increase feature variation.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
